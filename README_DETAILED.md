# EORA RAG Assistant

Помощник для ответов на вопросы потенциальных клиентов EORA по материалам сайта (кейсы/статьи).  
Поддерживает **три уровня сложности из ТЗ** и **два режима эмбеддингов**: оффлайн (без квот) и онлайн через OpenAI.

## Демо

- UI: `http://127.0.0.1:8000/ui/`  
  - Индексация из `links.txt` / поля ввода  
  - Выбор backend эмбеддингов: **local** или **openai**  
  - Выбор режима ответа: **simple / sources / inline / extractive**  
  - Лоадер при индексации/генерации, экспорт `.md`, кликабельные ссылки вида **\[1]** в inline-варианте  
- REST: `GET /health`, `POST /ingest`, `POST /ask`, `GET /docs`

---

## Стек

- **Python 3.11+** (разрабатывалось и тестировалось на 3.12)
- **FastAPI**, **Uvicorn**, **Jinja2**
- **SQLite** (локально, файл `rag.db`)
- **sentence-transformers** (оффлайн-эмбеддинги) / **OpenAI** (онлайн)
- **BeautifulSoup4** (парсинг HTML), **httpx** (загрузка)
- **Markdown** (рендер ответа с кликабельными \[n])

---

## Архитектура

```
            ┌──────────────┐
            │   Web UI     │  /ui
            └──────┬───────┘
                   │  (HTTP)
             ┌─────▼───────┐
             │  FastAPI    │  /ingest, /ask, /docs
             └─────┬───────┘
                   │
          ┌────────▼────────┐
          │  RAG Pipeline   │
          │  retrieve → gen │
          └────┬───────────┬┘
     embeddings│           │LLM (генерация)
   ┌───────────▼──┐   ┌────▼─────────┐
   │ local (ST)   │   │ OpenAI Chat  │
   │ (оффлайн)    │   │ (опционально)│
   └───────┬──────┘   └──────────────┘
           │
     ┌─────▼──────┐
     │   SQLite   │  docs, chunks, embeddings
     └────────────┘
```

---

## Что было сделано

- **Лёгкий** — краткий ответ по материалам.
- **Средний** — краткий ответ + блок `Источники: [1], [2]`.
- **Сложный** — **inline**-ссылки **\[1]** прямо в тексте в уместных местах (кликабельные).
- Дополнительно:
  - **Оффлайн режим** (локальные эмбеддинги без квот и ключей)
  - **Онлайн режим** (OpenAI embeddings/chat)
  - **links.txt** как основной источник ссылок
  - Дедупликация источников, защита от ошибок размерности эмбеддингов
  - Очистка HTML от мусора, заголовки страниц идут в контекст
  - Лоадер в UI, экспорт ответа в Markdown, REST-эндпоинты

---

## Установка и запуск

```bash
# 1) Клонирование репозитория
git clone <YOUR_REPO_URL> eora-rag
cd eora-rag

# 2) Создание и активация виртуального окружения
python -m venv .venv
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# 3) Установка зависимостей
pip install -r requirements.txt

# 4) Настройка окружения
cp .env.example .env

# 5) Индексация ссылок
python cli.py ingest --file links.txt
# или просто:
python cli.py ingest

# 6) Запуск сервера
uvicorn app.main:app --reload
# Открыть UI: http://127.0.0.1:8000/ui/
```

---

## Настройки (ENV)

Файл `.env` (см. `.env.example`):

```env
# OpenAI (нужно только для онлайн режима)
OPENAI_API_KEY=
OPENAI_CHAT_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Embeddings backend: local | openai
EMBEDDING_BACKEND=local
LOCAL_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# RAG
CHUNK_SIZE=400
CHUNK_OVERLAP=80
TOP_K=6
MAX_CONTEXT_CHARS=12000
TIMEOUT_SECONDS=30

# DB
SQLITE_PATH=rag.db

# Links
SEED_LINKS_FILE=links.txt
```

> Онлайн-режим требует валидный `OPENAI_API_KEY`. В оффлайн-режиме ключ не нужен.

---

## Индексация ссылок

**Предпочтительно** использовать `links.txt` в корне (по одной ссылке на строку, строки с `#` игнорируются):

```
# примеры
https://eora.ru/cases/chat-boty/hr-bot-dlya-magnit-kotoriy-priglashaet-na-sobesedovanie
https://eora.ru/cases/kazanexpress-poisk-tovarov-po-foto
https://eora.ru/cases/kazanexpress-sistema-rekomendacij-na-sayte
```

Варианты:
- **UI**: в блоке «Индексация» загрузите `links.txt` либо вставьте ссылки в текстовое поле.
- **CLI**:
  ```bash
  python cli.py ingest --file links.txt
  # или
  python cli.py ingest --urls https://... https://...
  # или (учтет SEED_LINKS_FILE):
  python cli.py ingest
  ```

---

## Использование

### Через UI

1. Откройте `http://127.0.0.1:8000/ui/`
2. При необходимости индексиpуйте ссылки (загрузите `links.txt`).
3. Задайте вопрос.  
4. Выберите режим:
   - **Лёгкий** — краткий ответ
   - **Средний** — ответ + `Источники: [1], [2]`
   - **Сложный** — inline \[1] прямо в тексте
   - **Оффлайн-конспект** — короткие выдержки без генерации LLM (на случай отсутствия ключа)
5. Нажмите **Ответить**.  
6. (Опционально) **Скачать .md** — экспорт видимого ответа.

### Через CLI

```bash
# Простой (inline) ответ
python cli.py ask -q "Что вы можете сделать для ритейлеров?" --mode inline

# Средний
python cli.py ask -q "Что вы можете сделать для ритейлеров?" --mode sources

# Лёгкий
python cli.py ask -q "Что вы можете сделать для ритейлеров?" --mode simple

# Оффлайн-конспект (без LLM)
python cli.py ask -q "Что вы можете сделать для ритейлеров?" --mode extractive

# Сохранить ответ в Markdown
python cli.py ask -q "..." --mode inline --out-md answer.md
```

---

## Что сработало, а что не очень

**Сработало:**
- Оффлайн-эмбеддинги (Sentence-Transformers) — **без квот** и стабильны.
- Inline-ссылки как **кликабельные \[n]**: Markdown-рендер + аккуратный пост-процессинг (одна ссылка — один раз).
- Заголовки страниц в контексте → чаще звучат **конкретные названия проектов**.
- `links.txt` вместо хардкода; дедупликация источников, лоадер в UI, экспорт `.md`.

**Не очень / ограничения:**
- Иногда LLM склонна к общим формулировкам. Мы смягчили это подсказками и контекстом, но полностью не устраняется без доп. техник (query-rewriting, more k, reranking).
- Очистка HTML: на отдельных страницах встречается мусор (встроенные формы/JSON) — фильтруем эвристиками, но идеально не всегда.
- Режим **inline** зависит от корректности выделения сущностей — добавили авто-вставку \[n] по ключевым словам, однако это эвристика.
- Онлайн через OpenAI требует активного ключа/доступа к моделям; возможны 403/429 при ограничениях тарифа.

---

## Что бы добавил, будь больше времени

- **Гибридный поиск**: объединить эмбеддинги + BM25 (SQLite FTS5) → лучше извлечение на коротких запросах.
- **SSE/streaming** ответов в UI (постепенная печать).
- **Суммаризация при индексации** (TL;DR каждого документа) для компактного контекста.
- **Автоматическое сканирование sitemap** и планировщик переиндексации.
- **Auth** в UI, ограничение доменов загрузки (allow-list), audit-лог.

---

## Структура репозитория

```
.
├── app/
│   ├── main.py           # FastAPI, маршруты + редирект / -> /ui/
│   ├── webui.py          # UI, формы ingest/ask, экспорт, Markdown→HTML
│   ├── ingest.py         # загрузка, парсинг, чанкинг, эмбеддинги, запись в БД
│   ├── rag.py            # retrieve + generate, inline-ссылки, режимы
│   ├── db.py             # SQLite, схемы таблиц, top-k по косинусной близости
│   ├── embeddings.py     # backend: local (ST) | openai
│   ├── utils.py          # html_to_text, очистка, постпроцессинг inline
│   ├── links.py          # links.txt: парсинг, чтение, resolve-приоритеты
│   ├── config.py         # pydantic settings (.env)
│   └── schemas.py        # Pydantic-схемы API
├── templates/
│   ├── base.html
│   └── index.html
├── static/
│   ├── style.css
│   └── app.js
├── cli.py                # CLI: ingest/ask
├── requirements.txt
├── .env.example
├── links.txt             # (пример) список ссылок
└── README.md             # этот файл
```

---

## Безопасность и чистота кода

- **Секреты** (ключ OpenAI) берутся из ENV/форм, не логируются.
- **CORS** ограничен базово (по умолчанию `*` для локалки; для прод — ограничить).
- **Парсинг HTML** удаляет `<script>`, `<style>`, `noscript`; вычищаем шум (массивы полей форм и пр.).
- **DB** — локальная, без сетевого доступа; транзакции, индексы.
- **Валидация форм** и input типов на стороне сервера.
- **Моды** ответов строго соответствуют ТЗ (inline — без блока «Источники» внизу).

---

## Траблшутинг

- **`PermissionDeniedError` / 403 / 429 (OpenAI)** — проверьте доступность модели в проекте/квоты; для старта используйте `EMBEDDING_BACKEND=local`.
- **`shapes (...) not aligned`** — база содержит старые эмбеддинги другой размерности. Удалите `rag.db` и переиндексируйте.
- **Страницы 404** — просто пропускаются и логируются как `WARN`.
- **Нет inline-ссылок в тексте** — постпроцессинг подставит \[n] по ключевым словам; при необходимости увеличьте `TOP_K`.

---
